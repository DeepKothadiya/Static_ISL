{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "from scipy import ndimage, signal\n",
    "from flowdec import data as fd_data\n",
    "from flowdec import psf as fd_psf\n",
    "from flowdec import restoration as fd_restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7502c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install DBUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = fd_data.neuron_25pct().data\n",
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2114cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.zeros_like(actual)\n",
    "for offset in [0, 1]:\n",
    "    kernel[tuple((np.array(kernel.shape) - offset) // 2)] = 1\n",
    "kernel = ndimage.gaussian_filter(kernel, sigma=1.)\n",
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = signal.fftconvolve(actual, kernel, mode='same')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = fd_restoration.RichardsonLucyDeconvolver(data.ndim, pad_min=np.ones(data.ndim)).initialize()\n",
    "res = algo.run(fd_data.Acquisition(data=data, kernel=kernel), niter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Note that deconvolution initialization is best kept separate from execution since the \"initialize\" \n",
    "# operation corresponds to creating a TensorFlow graph, which is a relatively expensive operation and\n",
    "# should not be repeated across iterations if deconvolving more than one image\n",
    "algo = fd_restoration.RichardsonLucyDeconvolver(data.ndim).initialize()\n",
    "res = algo.run(fd_data.Acquisition(data=data, kernel=kernel), niter=100).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3)\n",
    "axs = axs.ravel()\n",
    "fig.set_size_inches(18, 12)\n",
    "center = tuple([slice(None), slice(10, -10), slice(10, -10)])\n",
    "titles = ['Original Image', 'Blurred Image', 'Reconstructed Image']\n",
    "for i, d in enumerate([actual, data, res]):\n",
    "    img = exposure.adjust_gamma(d[center].max(axis=0), gamma=.2)\n",
    "    axs[i].imshow(img, cmap='Spectral_r')\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908ad35",
   "metadata": {},
   "source": [
    "#PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_noise(size, prob=0.1):\n",
    "    '''\n",
    "    Generates a matrix with uniform noise in the range [0-255] to be added to an image\n",
    "    \n",
    "    :param size: tuple defining the size of the noise matrix \n",
    "    :param prob: probability for the uniform noise generation \n",
    "    :type prob: float\n",
    "    :return matrix with uniform noise to be added to image\n",
    "    '''\n",
    "    \n",
    "    levels = int((prob * 255) // 2)\n",
    "    noise = np.random.randint(-levels, levels, size)\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imageio.imread(\"0.jpg\")\n",
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241850de",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_noise = uniform_noise(img.shape, prob=0.1)\n",
    "img_uni = np.clip(img.astype(int)+uni_noise, 0, 255)\n",
    "\n",
    "hist_img,_ = np.histogram(img, bins=256, range=(0,255))\n",
    "hist_uni,_ = np.histogram(img_uni, bins=256, range=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1726ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.bar(np.arange(256), hist_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_uni, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.bar(np.arange(256), hist_uni)\n",
    "\n",
    "#print(np.unique(img_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(size, mean=0, std=0.01):\n",
    "    '''\n",
    "    Generates a matrix with Gaussian noise in the range [0-255] to be added to an image\n",
    "    \n",
    "    :param size: tuple defining the size of the noise matrix \n",
    "    :param mean: mean of the Gaussian distribution\n",
    "    :param std: standard deviation of the Gaussian distribution, default 0.01\n",
    "    :return matrix with Gaussian noise to be added to image\n",
    "    '''\n",
    "    noise = np.multiply(np.random.normal(mean, std, size), 255)\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the noise matrix to be added\n",
    "gau_noise = gaussian_noise(img.shape, mean=0, std=0.05)\n",
    "\n",
    "# adding and clipping values below 0 or above 255\n",
    "img_gau = np.clip(img.astype(int)+gau_noise, 0, 255)\n",
    "\n",
    "hist_gau,_ = np.histogram(img_gau, bins=256, range=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_gau, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.bar(np.arange(256), hist_gau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1038f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impulsive_noise(image, prob=0.1, mode='salt_and_pepper'):\n",
    "    '''\n",
    "    Returns image with impulsive noise (0 and/or 255) to replace pixels in the image with some probability\n",
    "    \n",
    "    :param image: input image\n",
    "    :param prob: probability for the impulsive noise generation \n",
    "    :param mode: type of noise, 'salt', 'pepper' or 'salt_and_pepper' (default)\n",
    "    :type prob: float\n",
    "    :return noisy image with impulsive noise\n",
    "    '''\n",
    "\n",
    "    noise = np.array(image, copy=True)\n",
    "    for x in np.arange(image.shape[0]):\n",
    "        for y in np.arange(image.shape[1]):\n",
    "            rnd = np.random.random()\n",
    "            if rnd < prob:\n",
    "                rnd = np.random.random()\n",
    "                if rnd > 0.5:\n",
    "                    noise[x,y] = 255\n",
    "                else:\n",
    "                    noise[x,y] = 0\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae626f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_imp = impulsive_noise(img, prob=0.1)\n",
    "\n",
    "hist_imp,_ = np.histogram(img_imp, bins=256, range=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_imp, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.bar(np.arange(256), hist_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generating noise and subtracting it from the image\n",
    "uni_noise_new = uniform_noise(img.shape, prob=0.1)\n",
    "img_uni_res = img_uni - uni_noise_new\n",
    "\n",
    "def rmse(f,g):\n",
    "    size = f.shape\n",
    "    return np.sqrt(np.sum(np.square(f-g))/(size[0]*size[1]))\n",
    "\n",
    "print(\"Error between noisy and original: %.3f%%\" % (rmse(img.astype(float), img_uni.astype(float))))\n",
    "print(\"Error between 'restored' and original: %.3f%%\" % (rmse(img_uni_res.astype(float), img.astype(float))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(img_uni, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(img_uni_res, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the fft algorithms\n",
    "# including the transform, inverse and the shift methods\n",
    "from scipy.fftpack import fftn, ifftn, fftshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20833ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_imp = impulsive_noise(img, prob=0.05)\n",
    "\n",
    "w_mean3 = np.ones([3,3])/float(3*3)\n",
    "img_mean = fft_imagefilter(img_imp, w_mean3)\n",
    "img_median = medianfilter(img_imp, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93b31e",
   "metadata": {},
   "source": [
    "#PART 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "from scipy.ndimage import correlate1d\n",
    "from dphutils import scale\n",
    "import scipy.signal\n",
    "from timeit import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aaac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install DBUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-2,2,0.05)\n",
    "\n",
    "# parameter sigma is related to the dispersion of the values\n",
    "sigma1 = 0.3\n",
    "gauss1d_1 = (1/(sigma1*np.sqrt(2*np.pi))) * np.exp(-(np.square(x/sigma1)/2))\n",
    "\n",
    "sigma2 = 0.1\n",
    "gauss1d_2 = (1/(sigma2*np.sqrt(2*np.pi))) * np.exp(-(np.square(x/sigma2)/2))\n",
    "\n",
    "plt.plot(x, gauss1d_1, 'r') # larger sigma, 0.3\n",
    "plt.plot(x, gauss1d_2, 'b') # smaller sigma, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad01456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(k=5, sigma=1.0):\n",
    "    ''' Gaussian filter\n",
    "    :param k: defines the lateral size of the kernel/filter, default 5\n",
    "    :param sigma: standard deviation (dispersion) of the Gaussian distribution\n",
    "    :return matrix with a filter [k x k] to be used in convolution operations\n",
    "    '''\n",
    "    arx = np.arange((-k // 2) + 1.0, (k // 2) + 1.0)\n",
    "    x, y = np.meshgrid(arx, arx)\n",
    "    filt = np.exp(-(1/2) * (np.square(x) + np.square(y)) / np.square(sigma))\n",
    "    return filt / np.sum(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e64b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = gaussian_filter(k=5, sigma=0.9)\n",
    "print(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = gaussian_filter(k=9, sigma=1.5)\n",
    "plt.imshow(g2, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae94c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = imageio.imread(\"0.jpg\")\n",
    "h = gaussian_filter(k=7, sigma=2.5)\n",
    "\n",
    "# computing the number of padding on one side\n",
    "a = int(f.shape[0]//2 - h.shape[0]//2)\n",
    "h_pad = np.pad(h, (a,a-1), 'constant', constant_values=(0))\n",
    "\n",
    "# computing the Fourier transforms\n",
    "F = fftn(f)\n",
    "H = fftn(h_pad)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(fftshift(np.log(np.abs(F)+1)), cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(fftshift(np.log(np.abs(H)+1)), cmap=\"gray\")\n",
    "\n",
    "# convolution\n",
    "G = np.multiply(F,H)\n",
    "\n",
    "# Inverse Transform\n",
    "# - we have to perform FFT shift before reconstructing the image in the space domain\n",
    "g = fftshift(ifftn(G).real)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(f, cmap=\"gray\", vmin=0, vmax=128); plt.title(\"original image\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(g, cmap=\"gray\", vmin=0, vmax=128); plt.title(\"degraded/blurred image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e2839",
   "metadata": {},
   "source": [
    "Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219eb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the model\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# imports for the dataset\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "#os.chdir('D:/Traffic_Sign_Recognition')\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,DirectoryIterator\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 5\n",
    "cur_path = 'data1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27788bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = os.path.join('data1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e637581",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(validation_split = 0.2)\n",
    "#test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(dir_,target_size=(32,32),\n",
    "                                                   batch_size= 1920,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True,\n",
    "                                                   subset = 'training')\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(dir_,\n",
    "                                                          target_size = (32,32),\n",
    "                                                          batch_size = 480,\n",
    "                                                          class_mode = 'categorical',\n",
    "                                                          shuffle=True,\n",
    "                                                          subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf82c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = next(train_generator)\n",
    "x_test, y_test  = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ec113",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,str(i))\n",
    "    print(path)\n",
    "    images = os.listdir(path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '/'+ a)\n",
    "            image = image.resize((32,32))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db055e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4726cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = (x_train / 255.0).astype(np.float32)\n",
    "# x_test  = (x_test  / 255.0).astype(np.float32)\n",
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a pre-built ResNet50 w/o the top layer (classifer) and input shape configured for 128 x 128\n",
    "base = ResNet50(include_top=False, input_shape=(128, 128, 3), pooling='max')\n",
    "\n",
    "# Add a new classifier (top) layer for the 10 classes in CIFAR-10\n",
    "outputs = Dense(36, activation='softmax')(base.output)\n",
    "\n",
    "# Rebuild the model with the new classifier\n",
    "resnet = Model(base.input, outputs)\n",
    "#resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c064e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pre-stem as a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# Add the ResNet50 model as the remaining layers and rebuild\n",
    "model.add(resnet)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['acc'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_train, y_train, epochs=20, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ef2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5607d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=[6,5])\n",
    "plt.plot(history.history['acc'],'C1',linewidth=3.0)\n",
    "plt.plot(history.history['val_acc'],'C0',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=10)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.plot(history.history['loss'],'C1',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'C0',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=10)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_arg=np.argmax(y_test,axis=1)\n",
    "Y_pred = np.argmax(model.predict(x_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "cm=confusion_matrix(y_test_arg, Y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='BuGn', ax=ax)\n",
    "\n",
    "ax.set_title('Confusion Matrix for Sign Language Recognition \\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "#ax.xaxis.set_ticklabels(['0', '1', '2']); ax.yaxis.set_ticklabels(['0', '1', '2']);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
